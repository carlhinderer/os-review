-------------------------------------------------
CHAPTER 5 - CPU SCHEDULING
-------------------------------------------------

- Basic Concepts

    1. CPU-IO Burst Cycle 
         - CPU executes until it must wait (a CPU burst), usually for 
             completion of an IO request (an IO burst)

    2. CPU Scheduler
         - The CPU Scheduler (aka Short Term Scheduler) selects a process in
             memory that is ready to execute and allocates a CPU to it

    3. Preemptive Scheduling
         - Scheduling decisions must be made when:
             1. The process switches from 'Running' to 'Waiting' due to io or wait()
             2. The process switches from 'Running' to 'Ready' due to an interrupt
             3. The process switches from 'Waiting' to 'Ready' due to io completion
             4. The process terminates

         - If scheduling only occurs with #1 and #4, the scheduling scheme is 
             'non-preemptive'.  If scheduling also occurs at #2 or #3, the scheme is
             'preemptive'.

         - To avoid data inconsistensies that could arise from pre-empting the 
             execution of system calls, UNIX systems wait for a system call to 
             complete before doing a context switch.

    4. Dispatcher
         - The 'dispatcher' is the module that gives control of the CPU to a 
             process picked by the CPU scheduler.

         - The dispatcher is responsible for:
             1. Switching context
             2. Switching to user mode
             3. Jumping to the proper location to restart execution

         - The time it takes to stop one process and start another one is called
             'dispatch latency'.


- Criteria for Scheduling Algorithms

    1. CPU Utilization = amount of time CPU is in use
    2. Throughput = number of processes completed per time unit
    3. Turnaround time = how long it takes to execute a process
    4. Waiting Time = amount of time CPU sits idle
    5. Response Time = amount of time for UI to start responding again


- FCFS Algorithm
    - All processes are put into a FIFO queue
    - Easy to write and understand


- Shortest Job First (SFJ) Algorithm
    - Theoretical algorithm: just always pick the process with the shortest CPU burst
    - Optimal waiting time
    - Cannot actually be implemented by short term scheduler.  Some long term schedulers 
        will actually try to predict bursts by looking at previous bursts, though.


- Priority Scheduling
    - Includes class of algorithms that assigns priorities to processes to make
        scheduling decisions
    - One problem that can arise is 'starvation', when a lower priority process never
        runs, because higher priority processes are always blocking it.  One solution
        is to 'age' processes by increasing their priority over time.


- Round-Robin Scheduling
    - A 'time quantam' is defined, and processes are put into a FIFO queue.  Then each
        process in the queue is executed for the time quantam, then put a the back
        of the queue.


- Multilevel Queue Scheduling
    - Multiple queues are used, each with different priorities
        - System Processes (Highest)
        - Interactive Processes
        - Interactive Editing Processes
        - Batch Processes
        - Student Proesses (Lowest)


- Multilevel Feedback-Queue Scheduling
    - Multiple queues, processes can move between them depending on whether they have
        long CPU or IO bursts


- Multi-Processor Scheduling

    - Asymmetric Multiprocessing
        - All scheduling decisions, I/O processing, system activities are done by a 
            master processor.  
        - The other processors only run user code.

    - Symmetric Multiprocessing (SMP)
        - Each processor is self-scheduling.

    - Processor Affinity
        - One problem is that every time you switch processes on a  processor, you have to 
            clear the CPU cache for that processor, and this is expensive.  So, there are 
            strategies to avoid this.
        - 'Soft affinity' is a strategy in which the scheduler will attempt to keep 
            proceeses on one CPU.
        - 'Hard affinity' is when the OS guarantees the process will stay on one CPU.

    - Load Balancing
        - How to balance workload evenly across all processes?  We can
        either push tasks to CPUs becoming idle or pull tasks from busy CPUs.

    - Symmetric Multithreading
        - Strategy to run several threads on virtual processors rather than physical ones.
        - This is a hardware feature, not one provided by the os.  Intel processors call this 
            'hyperthreading'.


- Thread Scheduling

    - Since user threads are mapped to kernel threads, there is an additional layer of 
        complexity when trying to schedule the user threads.

    - The strategy known as 'Process Contention Scope' tries to resolve conflicts among 
        competing user threads on the same kernel thread.

    - The 'System Contention Scope' strategy is used to schedule the kernel threads 
        themselves.