-------------------------------------------------
CHAPTER 6 - PROCESS SYNCHRONIZATION
-------------------------------------------------

- Background

    We pointed out before that our bounded buffer solution allows at most
      BUFFER_SIZE - 1 items in the buffer at the same time.  Let's say we add an
      integer variable 'counter' to remedy this problem.


    /* Producer Process */
    while (true) {
        /* Produce an item in nextProduced */
        while (counter == BUFFER_SIZE) ;
        buffer[in] = nextProduced;
        in = (in + 1) % BUFFER_SIZE;
        counter++;
    }


    /* Consumer Process */
    while (true) {
        while (counter == 0) ;
        nextConsumed = buffer[out];
        out = (out + 1) % BUFFER_SIZE;
        counter--;
        /* Consume an item in nextConsumed */
    }


    These processes are implemented correctly, but they may not execute correctly
      if they are running concurrently.  A 'race condition' occurs when the 
      outcome of execution depends on the order of when data accesses take place.
      To avoid these, some mechanism is required to ensure only one process 
      alters the value of 'counter' at a time.


- The Critical Section Problem

    - A 'critical section' is a segment of code in which a process may be
        changing shared resources.

    - Each process must request permission to enter its critical section.  The
        section of code implementing this request is the 'entry section'.

    - The critical section may be followed by an 'exit section'.

    - The remainder of the code is the 'remainder section'.


    do {
        ENTRY_SECTION

        CRITICAL_SECTION

        EXIT_SECTION

        REMAINDER_SECTION
    } while(TRUE);


- Solving the Critical Section Problem

    A solution to the Critical Section Problem must satisfy 3 requirements:

      1. Mutual Exclusion = If P1 is executing in its critical section, then no
           other processes can be executing in their critical sections.

      2. Progress = If no process is executing its critical section, and some 
           processes wish to enter their critical sections, then those processes
           can participate in the decision on which will enter the critical 
           section next, and this selection cannot be postponed indefinitely.

      3. Bounded Waiting = There exists a limit to the number of times that other
           processes are allowed to enter their critical sections after a
           process has made the request.


- Peterson's Solution

    We have 2 processes, Pi and Pj, and they alternate execution between their
      critical and remainder sections.  We use two data items that are shared
      between the 2 processes:

      int turn;            /* Whose turn it is (i or j) */
      boolean flag[2];     /* Indicates whether a process is ready to enter its CS */


    Here is the structure of the solution (for process Pi):

      do {
          flag[i] = TRUE;
          turn = j;
          while (flag[j] && turn == j) ;

          CRITICAL_SECTION

          flag[i] = FALSE;

          REMAINDER_SECTION
      } while (TRUE);


    If 2 assignments of 'turn' occur at the same time, one will overwrite the other one.
       The eventual value of 'turn' determines which process is permitted to enter its
       critical section first.



- Locks

    In general, any solution to the critical section problem requires some kind of lock.
      A process must acquire a lock before entering a critical section.  It releases its
      lock when it exits the critical section.


    do {
        ACQUIRE_LOCK

        CRITICAL_SECTION

        RELEASE_LOCK

        REMAINDER_SECTION
    } while (TRUE);



- Synchronization Hardware

    There are a few different ways to provide locks using hardware.

    - If you have a non-preemptive kernel and a single CPU, can just disable
        interrupts when a shared variable is being modified.

    - Many modern computers have special instructions that allow us to test
        and modify the contents of a word, or to swap the contents of two words,
        atomically.


      /* TestAndSet instruction */
      boolean TestAndSet(boolean *target) {
          boolean rv = *target;
          *target = TRUE;
          return rv;
      }

      /* Mutual-exclusion implementation with TestAndSet() */
      do {
          while (TestAndSetLock(&lock)) ;

          CRITICAL_SECTION

          lock = false;

          REMAINDER_SECTION
      }


      /* Swap instruction */
      void Swap(boolean *a, boolean *b) {
          boolean temp = *a;
          *a = *b;
          *b = temp;
      }

      /* Mutual-exclustion implementation with Swap() */
      do {
          key = TRUE;
          while (key == TRUE) {
              Swap(&lock, &key);

              CRITICAL_SECTION
          }

          lock = FALSE;

          REMAINDER_SECTION
      } while (TRUE);



- Bounded Waiting TestAndSet()

    The algorithms above guarantee mutual exclusion, but they do not 
      guarantee bounded waiting.  Here is a modified version that does:


    /* Bounded Waiting TestAndSet() */
    boolean waiting[n];
    boolean lock;

    do {
        waiting[i] = TRUE;
        key = TRUE;
        while (waiting[i] && key) {
            key = TestAndSet(&lock);
        }
        waiting[i] = FALSE;

        CRITICAL_SECTION

        /* This guarantees the bounding waiting requirement is met, 
        *    because each waiting process has to wait n-1 turns at most.
        */
        j = (i + 1) % n;
        while ((j != i) && !waiting[j]) {
            j = (j + 1) % n;
        }

        if (j == i) {
            lock = FALSE;
        } else {
            waiting[j] = FALSE;
        }

        REMAINDER_SECTION
    }



- Semaphores

    The hardware-based solutions above are hard to use for application
      programmers, so we can use 'semaphores' to overcome this.  A semaphore
      is an integer variable that has two standard operations: wait() and
      signal().  


    wait(S) {
        while (S <= 0) ;
        S--; 
    }

    signal(S) {
        S++;
    }


    All the code in the wait and signal operations must be executed indivisbly,
      so no 2 processes can modify the semaphore at the same time.



- Types of Semaphores

    - The value of a 'counting semaphore' can range over an unrestricted
        domain.

    - The value of a 'binary semaphore' can only be 0 or 1.  These are also
        known as 'mutex locks'.



- Semaphores With Spinlocks

    Lets assume we have process P1 (which contains statement S1) and process
      P2 (which contains statement S2).  We require that S2 can begin 
      executing only after S1 is finished.

    We can do this by having P1 and P2 share a common semaphore 'synch', 
      which is initialized to 0.  


    /* Process P1 */
    S1;
    signal(synch);

    /* Process P2 */
    wait(synch);
    S2;


    /* Mutual exclusion with semaphores */
    do {
        waiting(mutex);

        CRITICAL_SECTION

        signal(mutex);

        REMAINDER_SECTION
    } while (TRUE);


    The main disadvantage with this approach is that is requires 'busy waiting'.  
      This type of semaphore is called a 'spinlock', since the CPU keeps spinning
      waiting for the lock to release.  They are useful, but meant to be used when
      the lock will be held for a short amount of time.



- Semaphores Without Spinlocks

    To overcome the need for busy waiting, we can modify the wait() and signal()
      operations.  When a wait() operation gets a negative semaphore value, it must
      wait.  

    But instead of busy waiting, the process can block itself.  The 'block'
      operation puts the process into a waiting queue associated with the semaphore,
      and the process is switched into 'Waiting' state.  Later, the 'wakeup'
      operation will resume execution of the process when it is scheduled by the 
      CPU scheduler.


    /* Semaphore struct */
    typedef struct{
        int value;
        struct process *list;     /* List of PCBs */
    } semaphore;


    /* Wait operation */
    wait(semaphore *S) {
        S->value--;
        if (S->value < 0) {
            ADD_PROCESS_TO S->list;
            block();
        }
    }


    /* Signal operation */
    signal(semaphore *S) {
        S->value++;
        if (S->value >= 0) {
            REMOVE PROCESS P FROM S->list;
            wakeup(P);
        }
    }



- Deadlocks

    The implementation of a semaphore with a waiting queue may result in a 
      'deadlock', in which processes are waiting for an event that never occurs.
      For example, if we have 2 processes, P0 and P1,


             P0            P1
         ----------    ----------
          wait(S);      wait(Q);
          wait(Q);      wait(S);
            ...           ...
         signal(S);    signal(Q);
         signal(Q);    signal(S);


- Starvation

    'Starvation' occurs if a process is kept waiting indefinitely, such as if a
      stack was used instead of a quene.



- The Bounded Buffer Problem

    - We assume we have a pool of n buffers, each capable of holding one item.

    - The 'mutex' semaphore provides mutual exclusion for accesses to the buffer
        pool.  It is initialized to 1.

    - The 'empty' and 'full' semaphores count the number of empty and full buffers.
        'empty' is initialized to n.  'full' is initialized to 0.


    Note the symmetry between the producer and consumer processes.  We can interpret
      this code as the producer producing full buffers for the consumer or as the
      consumer producing empty buffers for the producer.


    /* Producer process */
    do {
        // Produce an item in nextp

        wait(empty);
        wait(mutex);

        // Add nextp to buffer

        signal(mutex);
        signal(full);
    } while (TRUE);


    /* Consumer process */
    do {
        wait(full);
        wait(mutex);

        // Remove an item from buffer to nextc

        signal(mutex);
        signal(empty);

        // Consume the item in nextc
    } while (TRUE);